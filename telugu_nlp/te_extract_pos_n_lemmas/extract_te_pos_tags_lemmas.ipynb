{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"colab":{"name":"extract_te_pos_tags_lemmas.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"fbVP-qIxaasu"},"source":["### Extracting POS Tags and Lemmatize the words - Telugu\n","\n","**Notebook Author:** Nirupam Purushothama\n","\n","1. Using the [library code](https://bitbucket.org/sivareddyg/telugu-part-of-speech-tagger/src/master/) of IIIT-LTRC research team to extract the POS Tags and Lemmas of words \n","2. That library code is not updated to work with Python3.xx\n","3. I modified the code to work with Python3.xx and also work as a library for my use\n","\n","I am checking in the code as part of my repository because my changes are temporary and will work with my code. For any latest updates you should refer to the IIIT-LTRC code for latest updates. The code here is just "]},{"cell_type":"code","metadata":{"id":"TE2hUx3Raasv","executionInfo":{"status":"ok","timestamp":1624360229290,"user_tz":-330,"elapsed":4,"user":{"displayName":"lavan mooga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUsttETKEDzuOBMDvUlndHyxz0_l7jznzNkCtxmQ=s64","userId":"13660732577687726278"}}},"source":["import os, sys, inspect\n","import importlib\n","current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n","parent_dir = os.path.dirname(current_dir)\n","grandparent_dir = os.path.dirname(parent_dir)\n","lib_dir = parent_dir + \"/lib/lang_tools_te/bin\"\n","\n","if grandparent_dir not in sys.path:\n","    sys.path.insert(0, grandparent_dir)\n","    \n","if lib_dir not in sys.path:\n","    sys.path.insert(0, lib_dir)"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"id":"eAM5yFCpaasx","executionInfo":{"status":"error","timestamp":1624360231624,"user_tz":-330,"elapsed":16,"user":{"displayName":"lavan mooga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUsttETKEDzuOBMDvUlndHyxz0_l7jznzNkCtxmQ=s64","userId":"13660732577687726278"}},"outputId":"dec4dfdc-1fb3-4c9a-c4d9-ea8d4d84af97"},"source":["import unitok_lib as unlib\n","importlib.reload(sys.modules['unitok_lib'])\n","import te_helpers as tehp\n","importlib.reload(sys.modules['te_helpers'])\n","import lemmatiser as lmt\n","importlib.reload(sys.modules['lemmatiser'])\n","import tag2vert as tv\n","importlib.reload(sys.modules['tag2vert'])"],"execution_count":2,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-67339ee88fe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0munitok_lib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0munlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unitok_lib'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mte_helpers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtehp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'te_helpers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlemmatiser\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlmt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'unitok_lib'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"DzzaM0DealxQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nce72NzoapVN"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Uf2JLexaasz"},"source":["import json\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"equ6mToYaasz"},"source":["# Temp file names\n","words_tmp_file_name = \"telugu_words.tmp\"\n","tagger_op_file = \"tagger_out.tmp\"\n","\n","# Tagger file path\n","lang_tools_path = \"../lib/lang_tools_te\"\n","tagger_file_path = lang_tools_path + \"/bin/tnt\"\n","models_path = lang_tools_path + \"/models/telugu\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hWx_GPlkaasz"},"source":["### The way these functions work are as follows:\n","1. Convert input sentences to tokens using unitok.py\n","2. Take these tokens and then get their POS tags using ./bin/tnt (unfortunately this has to be run like a script)\n","3. Then using this output call lemmatizer and get the lemmatized words\n","4. Then massage this data using tag2vert "]},{"cell_type":"code","metadata":{"id":"Qyp6G9ydaas0"},"source":["def write_to_tmp_file(te_list):\n","    with open(words_tmp_file_name, 'w', encoding='utf-8') as file: \n","        file.write(\"<doc>\\n\")\n","        \n","        for word in te_list:\n","            file.write(word+\"\\n\")\n","        \n","        file.write(\"</doc>\")\n","        \n","    return\n","\n","def run_tagger_script():\n","    os.system(tagger_file_path + \" -H -v0 \"+ models_path + \" \" + words_tmp_file_name + \n","              \" | sed -e 's/\\t\\+/\\t/g' > \" + tagger_op_file)\n","    \n","    return\n","\n","def read_tagger_output():\n","    texts_list = []\n","    \n","    with open(tagger_op_file, 'r', encoding='utf-8') as file:\n","        file.readline()\n","        for line in file:\n","            texts_list.append(line.strip())\n","            \n","        texts_list.pop()\n","            \n","    return texts_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sDttbRe5aas0"},"source":["te_string = \"రాముడు మంచి బాలుడు. అసలు పిల్లలను కనక ముందు ఇక్కడ కనాలా అక్కడ కనాలా అని బోలెడంత సంఘర్షణ. ఇప్పుడు అమెరికా పౌరసత్వం తీసుకొనే అవకాశం వస్తే తీసుకోవాలా వద్దా అనేది మరో పెద్ద సంఘర్షణ.\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLjTx74_aas1","outputId":"e4c269c3-732c-4678-f830-9737462cbeab"},"source":["te_list = unlib.tokenise(te_string, unlib.LANGUAGE_DATA['telugu']())\n","te_list = tehp.remove_non_words(te_list)\n","write_to_tmp_file(te_list)\n","run_tagger_script()\n","te_postags_list = read_tagger_output()\n","lmt.load_lemmatiser_default(lang_tools_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tagger script\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Kn7fcCp6aas2","outputId":"59a36aeb-126c-4d99-abc4-ecb4c8951c77"},"source":["for item in te_postags_list:\n","    word_tag = item.split('\\t')\n","    lemma = lmt.lemmatise_word(word_tag[0], word_tag[1])\n","    word, lemma_corr, pos_tag = tv.massage_lemma(word_tag[0], lemma, word_tag[1])\n","    print(word, lemma_corr, pos_tag)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["అసలు అసలు NN\n","పిల్లలను పిల్ల NN\n","కనక కనకం CC\n","ముందు ముందు NST\n","ఇక్కడ ఇక్కడ NST\n","కనాలా కను VM\n","అక్కడ అక్కడ NST\n","కనాలా కను VM\n","అని అని UT\n","బోలెడంత బోలెడంత QF\n","సంఘర్షణ సంఘర్షణ NN\n",". None SYM.punc....\n","ఇప్పుడు ఇప్పుడు NST\n","అమెరికా అమెరికా NNP\n","పౌరసత్వం పౌరసత్వం NN\n","తీసుకొనే తీసుకో VM\n","అవకాశం అవకాశం NN\n","వస్తే వచ్చు VM\n","తీసుకోవాలా తీసుకో VM\n","వద్దా వద్దు VM\n","అనేది అను UT\n","మరో మరో QF\n","పెద్ద పెద్ద JJ\n","సంఘర్షణ సంఘర్షణ NN\n",". None SYM.punc....\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wNzQRAzsaas2","outputId":"120008f6-2113-46d4-d1a6-7d3b2ed5c0ce"},"source":["from gensim.models import KeyedVectors\n","model_ft = KeyedVectors.load_word2vec_format('../wiki.te.vec', binary=False)\n","output = []\n","output.append(model_ft.wv.most_similar('తిన్న'))\n","print(output)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'gensim'","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m<ipython-input-71-eac2e1d41036>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel_ft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../wiki.te.vec'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'తిన్న'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"]}]},{"cell_type":"code","metadata":{"id":"6RyKBrXXaas2"},"source":[""],"execution_count":null,"outputs":[]}]}